{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels have been assigned and saved to updatedlabel.xlsx\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# label the subset \n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'data_output.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ensure the comments column is named correctly\n",
    "comments_column = 'comment'\n",
    "\n",
    "# Function to label each comment\n",
    "def label_comment(comment):\n",
    "    comment = comment.lower()\n",
    "    if 'doctor' in comment or 'consultant' in comment:\n",
    "        if 'student' not in comment and 'nurse' not in comment:\n",
    "            return 'Medical Doctor'\n",
    "    elif 'vet' in comment or 'veterinarian' in comment:\n",
    "        if 'student' not in comment and 'technician' not in comment:\n",
    "            return 'Veterinarian'\n",
    "    return 'Other'\n",
    "\n",
    "# Apply the labeling function to the first 25000 comments only\n",
    "df['Label'] = df[comments_column].iloc[:2500].apply(label_comment)\n",
    "\n",
    "# Apply the labeling function to the comments column\n",
    "# df['Label'] = df[comments_column].apply(label_comment)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "output_file_path = 'labelled_comments.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Labels have been assigned and saved to {output_file_path}\")\n",
    "\n",
    "# Read the labeled comments\n",
    "labeled_df = pd.read_excel(\"labelled_comments.xlsx\")\n",
    "\n",
    "# Ensure 'comment' column is string type and drop rows with missing comments\n",
    "labeled_df['comment'] = labeled_df['comment'].astype(str)\n",
    "labeled_df.dropna(subset=['comment', 'Label'], inplace=True)\n",
    "# labeled_df = labeled_df.dropna(subset=['comment'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(labeled_df.head())\n",
    "\n",
    "\n",
    "# Vectorize comments\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(labeled_df['comment'])\n",
    "\n",
    "# Encode labels\n",
    "y = labeled_df['Label']\n",
    "\n",
    "\n",
    "# import psycopg2\n",
    "# import openai\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Set your OpenAI API key\n",
    "# api_key = 'sk-proj-yHQNtf5BlPYDABhpUbCCT3BlbkFJ3qzn3YG4OjdertY1gMZi'\n",
    "# os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "# # Initialize OpenAI client\n",
    "# client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# # Database connection parameters\n",
    "# db_url = \"postgresql://niphemi.oyewole:W7bHIgaN1ejh@ep-delicate-river-a5cq94ee-pooler.us-east-2.aws.neon.tech/Vetassist\"\n",
    "\n",
    "# # Connect to the database\n",
    "# conn = psycopg2.connect(db_url)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Fetch data from the correct table\n",
    "# query = \"SELECT username, comments FROM reddit_usernames_comments;\"\n",
    "# cursor.execute(query)\n",
    "\n",
    "# # Convert to a DataFrame\n",
    "# data = cursor.fetchall()\n",
    "# df = pd.DataFrame(data, columns=['username', 'comment'])\n",
    "\n",
    "# # Drop rows with missing comments\n",
    "# df.dropna(subset=['comment'], inplace=True)\n",
    "\n",
    "# # Close the connection\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "\n",
    "# # Display the first few rows of the DataFrame\n",
    "# print(df.head())\n",
    "\n",
    "# # List to store labeled data\n",
    "# labeled_data = []\n",
    "\n",
    "# # Classify comments using OpenAI's API\n",
    "# for index, row in df.iterrows():\n",
    "    # username = row['username']\n",
    "    # comment = row['comment']\n",
    "    \n",
    "    # chat_completion = client.chat.completions.create(\n",
    "    #     messages=[\n",
    "    #         {\n",
    "    #             \"role\": \"user\",\n",
    "    #             \"content\": f\"Classify the following comment into one of the categories: 'Medical Doctor', 'Veterinarian', 'Other'.\\n\\nComment: {comment}\\n\\nCategory:\",\n",
    "    #         }\n",
    "    #     ],\n",
    "    #     model=\"gpt-3.5-turbo\",\n",
    "    # )\n",
    "    \n",
    "    # category = chat_completion['choices'][0]['message']['content'].strip()\n",
    "    # labeled_data.append((username, comment, category))\n",
    "    # print(f\"Username: {username}, Comment: {comment}, Classified as: {category}\")\n",
    "\n",
    "# # Create a DataFrame for the labeled data\n",
    "# labeled_df = pd.DataFrame(labeled_data, columns=['Username', 'Comment', 'Category'])\n",
    "\n",
    "# # Save the DataFrame to an Excel file\n",
    "# labeled_df.to_excel('labeled_comments.xlsx', index=False)\n",
    "# print(\"Data saved to labeled_comments.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
